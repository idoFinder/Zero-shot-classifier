{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeqsR7YgZbwFFss1fbJChJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Intro\n","- zero-shot background and motivation\n","- three aproaches to do it:  \n","    - Bert\n","    - NLI\n","    - Generative models (gpt)\n","- Small experiment + results\n"],"metadata":{"id":"sZYyCpT44qx4"}},{"cell_type":"markdown","source":["# Sentence Bert - Embedding based classification\n"],"metadata":{"id":"QR__t6PYlzJu"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"LpXUxi2kl6EO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","from torch.nn import functional as F\n","tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n","model = AutoModel.from_pretrained('deepset/sentence_bert')"],"metadata":{"id":"xcOyndMymIQt","executionInfo":{"status":"ok","timestamp":1706376902635,"user_tz":-120,"elapsed":5605,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"execution_count":123,"outputs":[]},{"cell_type":"code","execution_count":124,"metadata":{"id":"LWqJ3zE3eODu","executionInfo":{"status":"ok","timestamp":1706376905575,"user_tz":-120,"elapsed":434,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"outputs":[],"source":["sentence = 'The tool bar doesnt work on my mac, can you fix it?\"'\n","labels = ['Feature-request', 'Bug', 'Other']\n","\n","# run inputs through model and mean-pool over the sequence\n","# dimension to get sequence-level representations\n","inputs = tokenizer.batch_encode_plus([sentence] + labels,\n","                                     return_tensors='pt',\n","                                     pad_to_max_length=True)\n"]},{"cell_type":"markdown","source":["We use the batch tokenizer to get the tokenized representation of the sentence and the labels (we use padding to match the max lenghe sequence)"],"metadata":{"id":"-XdwdyzXo1AR"}},{"cell_type":"code","source":["inputs['input_ids'] ,inputs['input_ids'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dA8scyWAmhLQ","executionInfo":{"status":"ok","timestamp":1706376909210,"user_tz":-120,"elapsed":384,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"28fa7b15-9076-486f-e92b-6360e59e8a1d"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[  101,  1996,  6994,  3347,  2987,  2102,  2147,  2006,  2026,  6097,\n","           1010,  2064,  2017,  8081,  2009,  1029,  1000,   102],\n","         [  101,  3444,  1011,  5227,   102,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [  101, 11829,   102,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0],\n","         [  101,  2060,   102,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0]]),\n"," torch.Size([4, 18]))"]},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","source":["we got the input tokens for each element:\n","1 for the sentence and 3 for each label"],"metadata":{"id":"sKKkv7CdpMbZ"}},{"cell_type":"code","source":["input_ids = inputs['input_ids']\n","attention_mask = inputs['attention_mask']\n","output = model(input_ids, attention_mask=attention_mask)[0]\n","output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndcvYIdHmRll","executionInfo":{"status":"ok","timestamp":1706376925490,"user_tz":-120,"elapsed":734,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"c2e636c8-2ca4-4071-e84f-6bd58da760c7"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 18, 768])"]},"metadata":{},"execution_count":126}]},{"cell_type":"markdown","source":["For each input token, we gen an embedding with size 768"],"metadata":{"id":"m9yc2HZZqOmq"}},{"cell_type":"code","source":["sentence_rep = output[:1].mean(dim=1)\n","label_reps = output[1:].mean(dim=1)\n","\n","# try using the pooling layer\n","# output_pooling = model(input_ids, attention_mask=attention_mask)[1]\n","# sentence_rep = output_pooling[0].unsqueeze(0)\n","# label_reps = output_pooling[1:]\n","\n","sentence_rep.shape, label_reps.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08CujQIEqIu2","executionInfo":{"status":"ok","timestamp":1706376928923,"user_tz":-120,"elapsed":417,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"6df8f014-dbee-4156-9b7c-2844f2d97daa"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 768]), torch.Size([3, 768]))"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","source":["We apply average pooling on the sequence dim to get the final embedding rep for each element (sentence and labels)"],"metadata":{"id":"LFnjWCVFq49d"}},{"cell_type":"code","source":["# now find the labels with the highest cosine similarities to\n","# the sentence\n","similarities = F.cosine_similarity(sentence_rep, label_reps)\n","closest = similarities.argsort(descending=True)\n","for ind in closest:\n","    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEGPqt9EoxiN","executionInfo":{"status":"ok","timestamp":1706376936906,"user_tz":-120,"elapsed":385,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"e39945f6-a151-4789-e448-8a0b8ca91900"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["label: Bug \t similarity: 0.27688243985176086\n","label: Feature-request \t similarity: 0.13044913113117218\n","label: Other \t similarity: 0.01148887537419796\n"]}]},{"cell_type":"markdown","source":["The biggest disatvantage of using bert embedding for this task is the fact that it is uses contextual embedding, which make it harder to embed the single word (our label) in an informative way."],"metadata":{"id":"ODGFj7mcBYaH"}},{"cell_type":"markdown","source":["# NLI"],"metadata":{"id":"S4fBua9vtP_-"}},{"cell_type":"code","source":["# load model pretrained on MNLI\n","from transformers import BartForSequenceClassification, BartTokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n","model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')"],"metadata":{"id":"Kxvm7Lkh0w1G","executionInfo":{"status":"ok","timestamp":1706378807930,"user_tz":-120,"elapsed":16971,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["# pose sequence as a NLI premise and label (politics) as a hypothesis\n","premise = \"Thanks for the awesome demo!! loved it.\"\n","hypothesis = 'This text is Positive.'\n","\n","# run through model pre-trained on MNLI\n","input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')"],"metadata":{"id":"1_q3vobhtT-w","executionInfo":{"status":"ok","timestamp":1706378840696,"user_tz":-120,"elapsed":374,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"execution_count":150,"outputs":[]},{"cell_type":"code","source":["input_ids, input_ids.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TccCMfBe2Yor","executionInfo":{"status":"ok","timestamp":1706378843018,"user_tz":-120,"elapsed":706,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"1e093be4-c01d-44ff-fc9b-d2d0c3dd6a21"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[    0, 22086,    13,     5,  6344, 19592, 12846,  2638,    24,     4,\n","              2,     2,   713,  2788,    16, 25968,     4,     2]]),\n"," torch.Size([1, 18]))"]},"metadata":{},"execution_count":151}]},{"cell_type":"markdown","source":["The tokenizer encode both the premise and the hypothesis into a single vecore and uses the special token \"2\" has a seperator between the elements"],"metadata":{"id":"VO5upOZ53Joh"}},{"cell_type":"code","source":["logits = model(input_ids).logits\n","logits, logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZvGb9nd2mkP","executionInfo":{"status":"ok","timestamp":1706378845312,"user_tz":-120,"elapsed":1167,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"ebd3418a-71a0-4453-85cc-f546258057db"},"execution_count":152,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-1.9128, -0.1560,  1.7016]], grad_fn=<AddmmBackward0>),\n"," torch.Size([1, 3]))"]},"metadata":{},"execution_count":152}]},{"cell_type":"markdown","source":["Using the logits layer, we can get the logits for each label: contradiction (0), neutral (1), entailment (2)"],"metadata":{"id":"On9LX81n6Eze"}},{"cell_type":"code","source":["# we throw away \"neutral\" (dim 1) and take the probability of\n","# \"entailment\" (2) as the probability of the label being true\n","entail_contradiction_logits = logits[:,[0,2]]\n","probs = entail_contradiction_logits.softmax(dim=1)\n","true_prob = probs[:,1].item() * 100\n","print(f'Probability that the label is true: {true_prob:0.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbyM1QqB2WUw","executionInfo":{"status":"ok","timestamp":1706378850223,"user_tz":-120,"elapsed":399,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"292f325a-c675-4d9d-ba42-c80ce90392cf"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability that the label is true: 97.38%\n"]}]},{"cell_type":"markdown","source":["Let's make it work on a given list of categories"],"metadata":{"id":"khmwIdtu73dB"}},{"cell_type":"code","source":["import numpy as np\n","\n","def generic_nli_classifier(premise, possible_cotegories, verbose=False):\n","    probas = []\n","\n","    hypothesis_template = \"This text is about {label}.\"\n","\n","    for label in possible_cotegories:\n","        hypothesis = hypothesis_template.format(**{'label':label})\n","        input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n","        logits = model(input_ids).logits\n","\n","        entail_contradiction_logits = logits[:,[0,2]]\n","        probs = entail_contradiction_logits.softmax(dim=1)\n","        true_prob = probs[:,1].item()\n","\n","        probas.append(true_prob)\n","\n","    softmax_probas = np.exp(probas) / np.sum(np.exp(probas))\n","    predicted_label = possible_cotegories[np.argmax(softmax_probas)]\n","\n","    if verbose:\n","        print(f'\\nChosen category: {predicted_label}')\n","        for idx,label in enumerate(possible_cotegories):\n","            print(f'- label:{label} probability: {softmax_probas[idx]:0.2f}%')\n","\n","    return predicted_label\n"],"metadata":{"id":"kkITZ3HtH9zV","executionInfo":{"status":"ok","timestamp":1706381173686,"user_tz":-120,"elapsed":374,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"execution_count":200,"outputs":[]},{"cell_type":"code","source":["examples = [\n","# Example 1\n","{'premise' : \"The tool bar doesn't work on my mac, can you fix it?\",\n","'possible_cotegories' : ['Feature-request', 'Bug', 'Other']},\n","\n","# Example 2\n","{'premise' : \"Can you add AI assistant button on the left bar as well?\",\n","'possible_cotegories' : ['Feature-request', 'Bug', 'Other']},\n","\n","# Example 3\n","{'premise' : \"The tool bar doesn't work on my mac, its annoying\",\n","'possible_cotegories' : ['Positive', 'Neutral', 'Negative']},\n","\n","# Example 4\n","{'premise' : \"Thanks for the awesome demo!! loved it\",\n","'possible_cotegories' : ['Positive', 'Neutral', 'Negative']}\n","]\n","\n","\n","for idx, example in enumerate(examples):\n","\n","    premise = example['premise']\n","    possible_cotegories = example['possible_cotegories']\n","\n","    print(f'\\n\\nExample {idx + 1}')\n","    print(f'\\nPremis: {premise}')\n","    _ = generic_nli_classifier(premise, possible_cotegories, verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIrX4q_E07lE","executionInfo":{"status":"ok","timestamp":1706381553181,"user_tz":-120,"elapsed":6939,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"428c79eb-f96a-4554-d575-36cfc3446863"},"execution_count":215,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Example 1\n","\n","Premis: The tool bar doesn't work on my mac, can you fix it?\n","\n","Chosen category: Bug\n","- label:Feature-request probability: 0.30%\n","- label:Bug probability: 0.41%\n","- label:Other probability: 0.29%\n","\n","\n","Example 2\n","\n","Premis: Can you add AI assistant button on the left bar as well?\n","\n","Chosen category: Feature-request\n","- label:Feature-request probability: 0.50%\n","- label:Bug probability: 0.24%\n","- label:Other probability: 0.26%\n","\n","\n","Example 3\n","\n","Premis: The tool bar doesn't work on my mac, its annoying\n","\n","Chosen category: Negative\n","- label:Positive probability: 0.29%\n","- label:Neutral probability: 0.30%\n","- label:Negative probability: 0.41%\n","\n","\n","Example 4\n","\n","Premis: Thanks for the awesome demo!! loved it\n","\n","Chosen category: Positive\n","- label:Positive probability: 0.46%\n","- label:Neutral probability: 0.27%\n","- label:Negative probability: 0.27%\n"]}]},{"cell_type":"markdown","source":["One advanatge of this approach over the embedding based is that it produce probability"],"metadata":{"id":"xZ4a8Bsj_6qN"}},{"cell_type":"markdown","source":["# NLI using HG pipeline"],"metadata":{"id":"lD8QPng-lyaE"}},{"cell_type":"code","source":["from transformers import pipeline\n","classifier = pipeline(\"zero-shot-classification\",\n","                      model=\"facebook/bart-large-mnli\")"],"metadata":{"id":"XCQHk2-cxaNJ","executionInfo":{"status":"ok","timestamp":1706381227841,"user_tz":-120,"elapsed":18814,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}}},"execution_count":202,"outputs":[]},{"cell_type":"code","source":["sequence_to_classify = \"The tool bar doesn't work on my mac, can you fix it?\"\n","candidate_labels = ['Feature-request', 'Bug', 'Other']\n","hypothesis_template = \"This text is about {}.\"\n","res = classifier(sequence_to_classify, candidate_labels, hypothesis_template=hypothesis_template)\n","\n","print(res['labels'])\n","print(np.round(res['scores'],2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWJkjpNuLO9e","executionInfo":{"status":"ok","timestamp":1706381406908,"user_tz":-120,"elapsed":2090,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"11ebd487-c1fd-459c-b72e-ccc9e5f5f4fb"},"execution_count":213,"outputs":[{"output_type":"stream","name":"stdout","text":["['Bug', 'Feature-request', 'Other']\n","[0.4  0.31 0.29]\n"]}]},{"cell_type":"code","source":["sequence_to_classify = \"The tool bar doesn't work on my mac, its annoying\"\n","candidate_labels = ['Positive', 'Neutral', 'Negative']\n","\n","hypothesis_template = \"This text is about {}.\"\n","\n","res = classifier(sequence_to_classify, candidate_labels, hypothesis_template=hypothesis_template)\n","\n","print(res['labels'])\n","print(np.round(res['scores'],2))\n","\n","print(' \\n -------------- \\n')\n","\n","hypothesis_template = \"This text is {}.\"\n","\n","res = classifier(sequence_to_classify, candidate_labels, hypothesis_template=hypothesis_template)\n","\n","print(res['labels'])\n","print(np.round(res['scores'],2))\n","\n","\n","print(' \\n -------------- \\n')\n","\n","hypothesis_template = \"This sentiment of this text is {}.\"\n","\n","res = classifier(sequence_to_classify, candidate_labels, hypothesis_template=hypothesis_template)\n","\n","print(res['labels'])\n","print(np.round(res['scores'],2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VXE4ZFtRNlV","executionInfo":{"status":"ok","timestamp":1706381688633,"user_tz":-120,"elapsed":5026,"user":{"displayName":"Ido Finder","userId":"11903253054022112257"}},"outputId":"5b8e4ad0-b7a2-421b-9409-6dc3560d0d72"},"execution_count":218,"outputs":[{"output_type":"stream","name":"stdout","text":["['Negative', 'Neutral', 'Positive']\n","[0.64 0.2  0.16]\n"," \n"," -------------- \n","\n","['Negative', 'Positive', 'Neutral']\n","[0.78 0.12 0.1 ]\n"," \n"," -------------- \n","\n","['Negative', 'Neutral', 'Positive']\n","[0.86 0.09 0.05]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Rvn1kZwhRU0f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# OpenAI GPT"],"metadata":{"id":"P21P4osfQoso"}},{"cell_type":"code","source":["# TODO"],"metadata":{"id":"CSV6We0sQsXP"},"execution_count":null,"outputs":[]}]}